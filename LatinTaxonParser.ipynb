{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1D85wbv-zo-KvioT1UbAoGpl7UqWtjy2z",
      "authorship_tag": "ABX9TyPvv8kNiemPHHPJWxSpH1jZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliconger/eliconger/blob/main/LatinTaxonParser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eli Conger, Research for Reptile Taxonomy\n",
        "# Program to find Latin words within compound taxon names\n",
        "# using a dictionary of known Latin words and a Trie for fast substring lookup\n",
        "\n",
        "# Importing necessary modules\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import pandas as pd  # Import pandas for reading Excel files\n",
        "import numpy as np   # To handle NaN values robustly\n",
        "\n",
        "# Define a class for the Trie Node\n",
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}              # Dictionary to store child nodes\n",
        "        self.is_end_of_word = False     # Flag to indicate if node marks end of a valid word\n",
        "\n",
        "# Define a class for the Trie structure\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()         # Initialize root node\n",
        "\n",
        "    # Insert a word into the trie\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:              # Loop through each character in the word\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()  # Create a new node if character not found\n",
        "            node = node.children[char]            # Move to the child node\n",
        "        node.is_end_of_word = True     # Mark end of word\n",
        "\n",
        "    # Search for the longest substrings in a given text that are in the Trie\n",
        "    def search_substrings(self, text):\n",
        "        matches = []                                 # List to store all matches found\n",
        "        n = len(text)\n",
        "        for i in range(n):                           # Loop through each character index in the text\n",
        "            node = self.root\n",
        "            longest_match = None                     # To keep track of longest valid word match\n",
        "            j = i\n",
        "            while j < n and text[j] in node.children:\n",
        "                node = node.children[text[j]]         # Move to next character node\n",
        "                j += 1\n",
        "                if node.is_end_of_word:\n",
        "                    longest_match = (i, j, text[i:j]) # Update longest match if end of word reached\n",
        "            if longest_match:\n",
        "                matches.append(longest_match)        # Add only the longest match found at this start\n",
        "        return matches\n",
        "\n",
        "# Function to build a Trie from a list of Latin words --- in this case, they were previously extracted from excel file\n",
        "# Also performs optional morphological stemming of Latin word endings\n",
        "\n",
        "def build_trie(latin_words):\n",
        "    suffixes = [\"us\", \"um\", \"a\", \"is\", \"os\", \"es\", \"ata\", \"atus\", \"atae\", \"ae\", \"ior\", \"ens\"]\n",
        "    trie = Trie()                                  # Initialize a Trie\n",
        "    for word in latin_words:\n",
        "        word = word.lower()                        # Convert to lowercase\n",
        "        trie.insert(word)                          # Insert full word\n",
        "        for suffix in suffixes:\n",
        "            if word.endswith(suffix):\n",
        "                stem = word[:-len(suffix)]         # Strip suffix to get potential stem\n",
        "                if len(stem) > 2:                  # Only insert reasonable-length stems\n",
        "                    trie.insert(stem)              # Insert stem into the Trie\n",
        "    return trie\n",
        "\n",
        "# Function to tokenize a taxon using Trie matches\n",
        "# This version also uses scoring logic to prefer longer matches and avoid overlaps\n",
        "\n",
        "def tokenize_taxon(taxon, trie):\n",
        "    taxon = taxon.lower()                         # Normalize to lowercase\n",
        "    matches = trie.search_substrings(taxon)       # Find all matches using the Trie\n",
        "    matches.sort(key=lambda x: (x[0], -(x[1] - x[0])))  # Sort by start index, then longest match\n",
        "\n",
        "    tokens = []\n",
        "    used = [False] * len(taxon)                   # Track used indices to avoid overlaps\n",
        "\n",
        "    for start, end, word in matches:\n",
        "        if not any(used[start:end]):              # Only accept if no overlap with previous matches\n",
        "            tokens.append(word)                   # Add the word to the result\n",
        "            for i in range(start, end):\n",
        "                used[i] = True                    # Mark indices as used\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Function to count occurrences of Latin roots from parsed CSV file\n",
        "\n",
        "def count_latin_root_occurrences(csv_path):\n",
        "    df = pd.read_csv(csv_path)                    # Load parsed results from CSV\n",
        "    root_counts = defaultdict(int)                # Dictionary to count roots\n",
        "\n",
        "    for roots in df[\"Latin Roots\"]:\n",
        "        if isinstance(roots, str):                # Ensure value is a string before splitting\n",
        "            for root in roots.split(\",\"):\n",
        "                cleaned_root = root.strip()\n",
        "                if cleaned_root:\n",
        "                    root_counts[cleaned_root] += 1     # Increment count for each root\n",
        "\n",
        "    count_df = pd.DataFrame(\n",
        "        list(root_counts.items()),\n",
        "        columns=[\"Latin Root\", \"Count\"]\n",
        "    ).sort_values(by=\"Count\", ascending=False)\n",
        "\n",
        "    count_df.to_csv(\"latin_root_occurrences.csv\", index=False)  # Save to file\n",
        "    print(\"Latin root occurrences saved to 'latin_root_occurrences.csv'\")\n",
        "    return count_df\n",
        "\n"
      ],
      "metadata": {
        "id": "OCMPK4dK5jta"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Ask user for file paths\n",
        "    latin_path = input(\"Enter path to Latin words text file: \")  # Path to .txt file (one word per line)\n",
        "    taxon_path = input(\"Enter path to Excel file with taxons: \")  # Path to .xlsx file\n",
        "\n",
        "    # Read Latin words file (that were extracted from the og file) (one per line)\n",
        "    with open(latin_path, 'r', encoding='utf-8') as f:\n",
        "        latin_words = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    # Read taxons from Excel file, assume second column (index 1)\n",
        "    df = pd.read_excel(taxon_path)               # Read Excel file into DataFrame\n",
        "    #taxons = df.iloc[:, 1].dropna().astype(str).tolist()  # Get WHOLE second column, drop NaNs, convert to strings\n",
        "    #taxons = df.iloc[:, 1].dropna().astype(str).apply(lambda x: x.split()[1] if len(x.split()) > 1 else x).tolist() # Get only second word in cells\n",
        "    taxons = df.iloc[:, 1].dropna().astype(str).apply(lambda x: x.split()[-1]).tolist() # gets LAST word\n",
        "\n",
        "\n",
        "    # Build the Trie from Latin dictionary with stem variations\n",
        "    trie = build_trie(latin_words)\n",
        "\n",
        "    # Parse each taxon and print results\n",
        "    # for taxon in taxons:\n",
        "    #    parts = tokenize_taxon(taxon, trie)      # Tokenize using stem-aware Trie\n",
        "    #    print(f\"{taxon}: {parts}\")              # Display result\n",
        "\n",
        "    # Save results to CSV\n",
        "    output_data = [{\"Taxon\": taxon, \"Latin Roots\": \", \".join(tokenize_taxon(t, trie))} for t in taxons]\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "    output_df.to_csv(\"parsed_taxon_roots.csv\", index=False)\n",
        "    print(\"Results saved to 'parsed_taxon_roots.csv'\")\n",
        "\n",
        "    # Count occurrences and store in DataFrame\n",
        "    count_df = count_latin_root_occurrences(\"parsed_taxon_roots.csv\")\n",
        "\n",
        "    # Print first 5 most frequent Latin root occurrences\n",
        "    print(\"\\nTop 5 most frequent Latin roots:\")\n",
        "    print(count_df.head(5))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIoyy5EY2Uq9",
        "outputId": "c5a5093f-0fb5-4dc7-b1af-770fb2598ee5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path to Latin words text file: /content/extracted_words.txt\n",
            "Enter path to Excel file with taxons: /content/Latin Taxons, etym starts with\"Named after Latin\" .xlsx\n",
            "Results saved to 'parsed_taxon_roots.csv'\n",
            "Latin root occurrences saved to 'latin_root_occurrences.csv'\n",
            "\n",
            "Top 5 most frequent Latin roots:\n",
            "    Latin Root  Count\n",
            "53    gracilis     25\n",
            "77   fasciatus     21\n",
            "6    maculatus     17\n",
            "14    lineatus     15\n",
            "157    bicolor     14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "┌────────────────────────────┐\n",
        "│ Start Program (__main__)  │\n",
        "└────────────┬──────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Prompt user for Latin words (.txt)     │\n",
        "│ and taxon names file (.xlsx) paths     │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Read Latin words file → List[str]      │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Read Excel file                        │\n",
        "│ → Extract last word from each taxon    │\n",
        "│ → List[str] (taxons)                   │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Build Trie from Latin words            │\n",
        "│ • Insert full word                     │\n",
        "│ • Insert stemmed versions              │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ For each taxon in list:                │\n",
        "│ • Normalize                            │\n",
        "│ • Search Trie for longest substrings   │\n",
        "│ • Prioritize non-overlapping matches   │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Print taxon with identified Latin roots│\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Save results to 'parsed_taxon_roots.csv'│\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌────────────────────────────────────────┐\n",
        "│ Count occurrences of each Latin root   │\n",
        "│ → Save to 'latin_root_occurrences.csv' │\n",
        "└────────────┬───────────────────────────┘\n",
        "             │\n",
        "             ▼\n",
        "┌──────────────────────┐\n",
        "│ End Program          │\n",
        "└──────────────────────┘\n"
      ],
      "metadata": {
        "id": "PH36lB0owTqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}